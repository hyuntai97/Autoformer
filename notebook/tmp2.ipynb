{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from data_provider.data_factory import data_provider\n",
    "from exp.exp_basic import Exp_Basic\n",
    "# from models import Informer, Autoformer, Transformer\n",
    "from utils.tools import EarlyStopping, adjust_learning_rate, visual\n",
    "from utils.metrics import metric\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%matplotib` not found.\n"
     ]
    }
   ],
   "source": [
    "%matplotib inline\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -u run.py \\\n",
    "#   --is_training 1 \\\n",
    "#   --root_path ./dataset/ETT-small/ \\\n",
    "#   --data_path ETTh1.csv \\\n",
    "#   --model_id ETTh1_96_24 \\\n",
    "#   --model Autoformer \\\n",
    "#   --data ETTh1 \\\n",
    "#   --features M \\\n",
    "#   --seq_len 96 \\\n",
    "#   --label_len 48 \\\n",
    "#   --pred_len 24 \\\n",
    "#   --e_layers 2 \\\n",
    "#   --d_layers 1 \\\n",
    "#   --factor 3 \\\n",
    "#   --enc_in 7 \\\n",
    "#   --dec_in 7 \\\n",
    "#   --c_out 7 \\\n",
    "#   --des 'Exp' \\\n",
    "#   --itr 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_provider.data_loader import Dataset_ETT_hour, Dataset_ETT_minute, Dataset_Custom, Dataset_Pred\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_flag = True\n",
    "drop_last = True\n",
    "batch_size = 32\n",
    "freq = 'h'\n",
    "\n",
    "Data = Dataset_ETT_hour\n",
    "\n",
    "timeenc = 0\n",
    "\n",
    "root_path = '../dataset'\n",
    "data_path = 'ETTh1.csv'\n",
    "flag='train'\n",
    "seq_len = 96\n",
    "label_len = 48\n",
    "pred_len = 48\n",
    "features = 'S'\n",
    "target = 'OT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = Dataset_ETT_hour\n",
    "dataset = Data(root_path='../dataset',\n",
    "                data_path='ETTh1.csv',\n",
    "                flag='train',\n",
    "                size=[seq_len, label_len, pred_len],\n",
    "                features=features,\n",
    "                target=target,\n",
    "                timeenc=timeenc,\n",
    "                freq=freq)\n",
    "\n",
    "data_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle_flag,\n",
    "        num_workers=10,\n",
    "        drop_last=drop_last) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x, batch_y, batch_x_mark, batch_y_mark = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 96, 1])\n",
      "torch.Size([32, 96, 1])\n",
      "torch.Size([32, 96, 4])\n",
      "torch.Size([32, 96, 4])\n"
     ]
    }
   ],
   "source": [
    "print(batch_x.shape)\n",
    "print(batch_y.shape)\n",
    "print(batch_x_mark.shape)\n",
    "print(batch_y_mark.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x = batch_x.float().to(device)\n",
    "batch_y = batch_y.float().to(device)\n",
    "batch_x_mark = batch_x_mark.float().to(device)\n",
    "batch_y_mark = batch_y_mark.float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder input\n",
    "dec_inp = torch.zeros_like(batch_y[:, -pred_len:, :]).float()\n",
    "dec_inp = torch.cat([batch_y[:, :label_len, :], dec_inp], dim=1).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 96, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_inp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_enc = batch_x \n",
    "x_mark_enc = batch_x_mark\n",
    "x_dec = dec_inp \n",
    "x_mark_dec = batch_y_mark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.Autoformer_EncDec import series_decomp\n",
    "from layers.Embed import DataEmbedding, DataEmbedding_wo_pos\n",
    "from layers.Autoformer_EncDec import Encoder, Decoder, EncoderLayer, DecoderLayer, my_Layernorm, series_decomp\n",
    "\n",
    "from layers.AutoCorrelation import AutoCorrelation, AutoCorrelationLayer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decomp\n",
    "kernel_size = 25\n",
    "decomp = series_decomp(kernel_size)\n",
    "\n",
    "mean = torch.mean(x_enc, dim=1).unsqueeze(1).repeat(1, pred_len, 1)\n",
    "zeros = torch.zeros([x_dec.shape[0], pred_len, x_dec.shape[2]], device=x_enc.device)\n",
    "\n",
    "seasonal_init, trend_init = decomp(x_enc)\n",
    "\n",
    "# decoder input\n",
    "trend_init = torch.cat([trend_init[:, -label_len:, :], mean], dim=1)\n",
    "seasonal_init = torch.cat([seasonal_init[:, -label_len:, :], zeros], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 96, 1])\n",
      "torch.Size([32, 96, 1])\n"
     ]
    }
   ],
   "source": [
    "print(trend_init.shape)\n",
    "print(seasonal_init.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- encoding config \n",
    "enc_in = 1\n",
    "dec_in = 1\n",
    "d_model = 512\n",
    "embed = 'timeF'\n",
    "dropout = 0.05\n",
    "\n",
    "enc_embedding = DataEmbedding_wo_pos(enc_in, d_model, embed, freq,\n",
    "                                            dropout).to(device)\n",
    "dec_embedding = DataEmbedding_wo_pos(dec_in, d_model, embed, freq,\n",
    "                                            dropout).to(device)\n",
    "\n",
    "# enc\n",
    "enc_out = enc_embedding(x_enc, x_mark_enc)\n",
    "\n",
    "# dec\n",
    "dec_out = dec_embedding(seasonal_init, x_mark_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = 1\n",
    "n_heads = 8\n",
    "d_ff = 2048\n",
    "moving_avg = 25\n",
    "activation = 'gelu'\n",
    "e_layers = 2\n",
    "\n",
    "# Encoder\n",
    "encoder = Encoder(\n",
    "    [\n",
    "        EncoderLayer(\n",
    "            AutoCorrelationLayer(\n",
    "                AutoCorrelation(False, factor, attention_dropout=dropout,\n",
    "                                output_attention=False),\n",
    "                d_model, n_heads),\n",
    "            d_model,\n",
    "            d_ff,\n",
    "            moving_avg=moving_avg,\n",
    "            dropout=dropout,\n",
    "            activation=activation\n",
    "        ) for l in range(e_layers)\n",
    "    ],\n",
    "    norm_layer=my_Layernorm(d_model)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_out, attns = encoder(enc_out, attn_mask=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 96, 512])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "- 학습 이후에 Autoformer.py 수정해서 prediction plot 그리기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_out = 1\n",
    "d_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "decoder = Decoder(\n",
    "    [\n",
    "        DecoderLayer(\n",
    "            AutoCorrelationLayer(\n",
    "                AutoCorrelation(True, factor, attention_dropout=dropout,\n",
    "                                output_attention=False),\n",
    "                d_model, n_heads),\n",
    "            AutoCorrelationLayer(\n",
    "                AutoCorrelation(False, factor, attention_dropout=dropout,\n",
    "                                output_attention=False),\n",
    "                d_model, n_heads),\n",
    "            d_model,\n",
    "            c_out,\n",
    "            d_ff,\n",
    "            moving_avg=moving_avg,\n",
    "            dropout=dropout,\n",
    "            activation=activation,\n",
    "        )\n",
    "        for l in range(d_layers)\n",
    "    ],\n",
    "    norm_layer=my_Layernorm(d_model),\n",
    "    projection=nn.Linear(d_model, c_out, bias=True)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_part, trend_part = decoder(dec_out, enc_out, x_mask=None, cross_mask=None,\n",
    "                                            trend=trend_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 96, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seasonal_part.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 96, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trend_part.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 96, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final\n",
    "dec_out = trend_part + seasonal_part\n",
    "\n",
    "dec_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_out_np = dec_out.detach().cpu().numpy()\n",
    "batch_y_np = batch_y.detach().cpu().numpy()\n",
    "batch_x_np = batch_x.detach().cpu().numpy()\n",
    "seasonal_np =seasonal_part.detach().cpu().numpy()\n",
    "trend_np = trend_part.detach().cpu().numpy()\n",
    "\n",
    "pred = dec_out_np[:, -pred_len:, :]\n",
    "true = batch_y_np[:, -pred_len:, :]\n",
    "input = batch_x_np\n",
    "seasonal = seasonal_np \n",
    "trend = trend_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "plt.plot(seasonal[0].flatten())\n",
    "plt.savefig('./test.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seasonal[0].flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pred[0].flatten())\n",
    "plt.savefig('./test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tobigs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d67b72366f26532c5f661c017539146322738586d7661e09ffcd2c8ef92eec78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
